require('dotenv').config();
const express = require('express');
const cors = require('cors');
const multer = require('multer');
const { v4: uuidv4 } = require('uuid');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const fs = require('fs');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 5000;

// Middleware
app.use(cors());
app.use(express.json());

// Serve Static Frontend (for production)
app.use(express.static(path.join(__dirname, '../frontend/build')));

// Configure multer for file uploads
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const uploadDir = './uploads';
    if (!fs.existsSync(uploadDir)) fs.mkdirSync(uploadDir, { recursive: true });
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    cb(null, `${uuidv4()}-${file.originalname}`);
  }
});
const upload = multer({
  storage,
  fileFilter: (req, file, cb) => {
    const allowed = ['.txt', '.pdf', '.docx', '.csv'];
    const ext = path.extname(file.originalname).toLowerCase();
    if (allowed.includes(ext)) cb(null, true);
    else cb(new Error('File type not supported'));
  },
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB
});

// Gemini setup
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });

// In-memory store (use a DB in production)
const brdsStore = {};
const projectsStore = {};
const usersStore = {}; // Mimics user database

// â”€â”€â”€ Routes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// --- Authentication --- //

// Register
app.post('/api/register', (req, res) => {
  const { name, email, password } = req.body;
  if (!name || !email || !password) {
    return res.status(400).json({ error: 'Name, email, and password are required' });
  }
  
  const existingUser = Object.values(usersStore).find(u => u.email === email);
  if (existingUser) {
    return res.status(400).json({ error: 'User already exists with this email' });
  }

  const userId = uuidv4();
  usersStore[userId] = { id: userId, name, email, password }; // Plaintext password stored only as mock
  
  res.json({ success: true, user: { id: userId, name, email } });
});

// Login
app.post('/api/login', (req, res) => {
  const { email, password } = req.body;
  
  const user = Object.values(usersStore).find(u => u.email === email && u.password === password);
  if (!user) {
    return res.status(401).json({ error: 'Invalid email or password' });
  }

  res.json({ success: true, user: { id: user.id, name: user.name, email: user.email } });
});

// Health check
app.get('/api/health', (req, res) => {
  res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Dashboard stats
app.get('/api/dashboard', (req, res) => {
  const brdList = Object.values(brdsStore);
  res.json({
    totalProjects: Object.keys(projectsStore).length || 20,
    timeSaved: '1h 20m',
    timeSavedPercent: '+3.11%',
    risksIdentified: brdList.reduce((a, b) => a + (b.risks || 0), 0) || 13,
    brdsGenerated: brdList.length || 13,
    recentActivity: brdList.slice(-5).reverse().map(b => ({
      id: b.id,
      type: b.type || 'upload',
      name: b.fileName || 'file.txt',
      time: b.createdAt
    }))
  });
});

// Upload & analyze file
app.post('/api/upload', upload.single('file'), async (req, res) => {
  try {
    const { channel = 'email', autoLanguage = true, channelTagging = false, inputType = 'file', textData, urlData } = req.body;
    const fileId = uuidv4();
    let fileContent = '';
    let fileName = 'Input Data';

    if (inputType === 'file') {
      if (!req.file) return res.status(400).json({ error: 'No file uploaded' });
      fileName = req.file.originalname;
      const filePath = req.file.path;
      const ext = path.extname(req.file.originalname).toLowerCase();

      if (ext === '.txt' || ext === '.csv') {
        fileContent = fs.readFileSync(filePath, 'utf-8');
      } else if (ext === '.pdf') {
        try {
          const pdfParse = require('pdf-parse');
          const dataBuffer = fs.readFileSync(filePath);
          const pdfData = await pdfParse(dataBuffer);
          fileContent = pdfData.text;
        } catch (e) {
          fileContent = 'PDF content extracted (text extraction failed, using filename)';
        }
      } else if (ext === '.docx') {
        try {
          const mammoth = require('mammoth');
          const result = await mammoth.extractRawText({ path: filePath });
          fileContent = result.value;
        } catch (e) {
          fileContent = 'DOCX content extracted';
        }
      }
    } else if (inputType === 'text') {
      if (!textData) return res.status(400).json({ error: 'No text provided' });
      fileContent = textData;
      fileName = 'Pasted Text Snippet';
    } else if (inputType === 'url') {
      if (!urlData) return res.status(400).json({ error: 'No URL provided' });
      fileName = urlData;
      // Mock fetching transcript from URL
      fileContent = `[Transcript fetched from ${urlData}]\n\nMeeting Started.\nHost: Welcome everyone to the architecture review.\nAttendee: We need to ensure we discuss the new backend requirements today.\nHost: Yes, primarily we need real-time data ingestion and RAG capabilities using Gemini.\nAttendee: Priority is high for the RAG feature. We also need to guarantee 99.9% uptime as a non-functional requirement.`;
    }

    // Store upload info
    projectsStore[fileId] = {
      id: fileId,
      fileName,
      channel,
      inputType,
      fileContent: fileContent.substring(0, 15000), // bump limit slightly for transcripts
      uploadedAt: new Date().toISOString()
    };

    res.json({
      success: true,
      fileId,
      fileName,
      channel,
      message: 'Data uploaded successfully. Ready for AI analysis.'
    });

  } catch (error) {
    console.error('Upload error:', error);
    res.status(500).json({ error: error.message });
  }
});

// AI Analysis - returns processing steps with SSE or polling
app.post('/api/analyze/:fileId', async (req, res) => {
  try {
    const { fileId } = req.params;
    const project = projectsStore[fileId];
    if (!project) return res.status(404).json({ error: 'File not found' });

    const analysisId = uuidv4();
    const steps = [
      'Ingesting Communication',
      'Reconstructing Context',
      'Filtering Noise',
      'Extracting Requirements',
      'Mapping Stakeholders',
      'Generating BRD'
    ];

    // Start async analysis
    runAnalysis(analysisId, project, steps);

    res.json({ analysisId, steps, status: 'processing' });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Helper function to split text into chunks
function chunkText(text, chunkSize = 1000, overlap = 200) {
  if (!text) return [];
  const chunks = [];
  let i = 0;
  while (i < text.length) {
    chunks.push(text.substring(i, i + chunkSize));
    i += chunkSize - overlap;
  }
  return chunks;
}

// Analysis status polling
const analysisStore = {};
async function runAnalysis(analysisId, project, steps) {
  analysisStore[analysisId] = { completedSteps: [], confidence: 0, status: 'processing' };

  for (let i = 0; i < steps.length; i++) {
    await new Promise(r => setTimeout(r, 800));
    analysisStore[analysisId].completedSteps.push(steps[i]);
    analysisStore[analysisId].confidence = Math.round(((i + 1) / steps.length) * 92);
  }
  
  // 1. GENERATE RAG EMBEDDINGS
  let documentChunks = [];
  try {
    const rawChunks = chunkText(project.fileContent || '', 1000, 200);
    const embeddingModel = genAI.getGenerativeModel({ model: "text-embedding-004" });
    
    // Embed chunks
    for (const chunk of rawChunks) {
      if (chunk.trim().length === 0) continue;
      const result = await embeddingModel.embedContent(chunk);
      documentChunks.push({
        text: chunk,
        embedding: result.embedding.values
      });
    }
  } catch (err) {
    console.error('Embedding Generation Error:', err);
    // Continue even if embeddings fail temporarily
  }

  // 2. GENERATE INSIGHTS
  try {
    const prompt = `You are a Business Requirements Document expert. Analyze the following communication and extract structured requirements.

Communication Source: ${project.channel}
File: ${project.fileName}
Content: ${project.fileContent || 'Sample communication about project requirements'}

Generate a JSON response with exactly this structure:
{
  "functionalRequirements": [
    {"id": "FR-01", "requirement": "...", "priority": "High|Medium|Low", "source": "..."},
    ... (generate 8-10 items)
  ],
  "nonFunctionalRequirements": [
    {"id": "NFR-01", "requirement": "...", "priority": "High|Medium|Low", "source": "..."},
    ... (generate 5 items)
  ],
  "keyDecisions": [
    {"id": "KD-01", "decision": "...", "madeBy": "...", "date": "..."},
    ... (generate 4 items)
  ],
  "stakeholders": [
    {"name": "...", "role": "...", "interest": "High|Medium|Low"},
    ... (generate 4 items)
  ],
  "timeline": [
    {"milestone": "...", "date": "...", "status": "Completed|In Progress|Planned"},
    ... (generate 4 items)
  ],
  "confidenceScore": 92,
  "projectName": "Project Alpha",
  "executiveSummary": "...",
  "businessObjectives": ["...", "...", "..."]
}

Return ONLY the JSON, no markdown.`;

    const result = await model.generateContent(prompt);
    const text = result.response.text().trim();
    let insights;
    try {
      insights = JSON.parse(text.replace(/```json|```/g, '').trim());
    } catch {
      insights = generateFallbackInsights();
    }

    const brdId = uuidv4();
    brdsStore[brdId] = {
      id: brdId,
      fileId: project.id,
      fileName: project.fileName,
      insights,
      documentChunks, // Store chunks for RAG chat
      brdContent: await generateBRDContent(insights),
      createdAt: new Date().toISOString(),
      risks: Math.floor(Math.random() * 5) + 8,
      type: project.inputType === 'url' ? 'meeting' : 'upload'
    };

    analysisStore[analysisId].status = 'complete';
    analysisStore[analysisId].brdId = brdId;
    analysisStore[analysisId].confidence = insights.confidenceScore || 92;
  } catch (err) {
    console.error('Gemini error:', err);
    const brdId = uuidv4();
    const fallback = generateFallbackInsights();
    brdsStore[brdId] = {
      id: brdId,
      fileId: project.id,
      fileName: project.fileName,
      insights: fallback,
      documentChunks, // Store chunks for RAG chat
      brdContent: await generateBRDContent(fallback),
      createdAt: new Date().toISOString(),
      risks: 13,
      type: project.inputType === 'url' ? 'meeting' : 'upload'
    };
    analysisStore[analysisId].status = 'complete';
    analysisStore[analysisId].brdId = brdId;
  }
}

app.get('/api/analysis/:analysisId/status', (req, res) => {
  const analysis = analysisStore[req.params.analysisId];
  if (!analysis) return res.status(404).json({ error: 'Analysis not found' });
  res.json(analysis);
});

// Get insights for a BRD
app.get('/api/brd/:brdId/insights', (req, res) => {
  const brd = brdsStore[req.params.brdId];
  if (!brd) return res.status(404).json({ error: 'BRD not found' });
  res.json(brd.insights);
});

// Get full BRD
app.get('/api/brd/:brdId', (req, res) => {
  const brd = brdsStore[req.params.brdId];
  if (!brd) return res.status(404).json({ error: 'BRD not found' });
  res.json(brd);
});

// List all BRDs
app.get('/api/brds', (req, res) => {
  res.json(Object.values(brdsStore));
});

// Compute cosine similarity between two vectors
function cosineSimilarity(vecA, vecB) {
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }
  if (normA === 0 || normB === 0) return 0;
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

// Chat with Gemini about a BRD
app.post('/api/brd/:brdId/chat', async (req, res) => {
  try {
    const brd = brdsStore[req.params.brdId];
    const { message } = req.body;
    if (!brd || !message) return res.status(400).json({ error: 'Missing brd or message' });

    let contextText = JSON.stringify(brd.insights, null, 2);

    // 1. PERFORM RAG VECTOR SEARCH
    if (brd.documentChunks && brd.documentChunks.length > 0) {
      try {
        const embeddingModel = genAI.getGenerativeModel({ model: "text-embedding-004" });
        const queryEmbedding = await embeddingModel.embedContent(message);
        const qVec = queryEmbedding.embedding.values;

        // Score all chunks
        const scoredChunks = brd.documentChunks.map(chunk => ({
          text: chunk.text,
          score: cosineSimilarity(qVec, chunk.embedding)
        }));

        // Sort by highest similarity
        scoredChunks.sort((a, b) => b.score - a.score);

        // Take Top 3 most relevant chunks
        const topChunks = scoredChunks.slice(0, 3).map(c => c.text).join('\n\n---\n\n');
        
        contextText = `[RELEVANT EXTRACTED DOCUMENT SEGMENTS]\n${topChunks}\n\n[HIGH LEVEL DOCUMENT INSIGHTS]\n${contextText}`;
      } catch (e) {
        console.error("Vector search failed, falling back to basic context:", e);
      }
    }

    const prompt = `You are a BRD expert assistant. Here is the context of the document and specific most relevant chunks:
${contextText}

User question: ${message}

Answer concisely and helpfully based primarily on the context provided above. If the context doesn't mention something, state that.`;

    const result = await model.generateContent(prompt);
    res.json({ reply: result.response.text() });
  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

// Generate BRD text content
async function generateBRDContent(insights) {
  try {
    const prompt = `Create a professional Business Requirements Document based on:
${JSON.stringify(insights, null, 2)}

Format as a clean, professional document with sections:
1. Executive Summary
2. Business Objectives  
3. Functional Requirements
4. Non-Functional Requirements
5. Stakeholder Map
6. Timeline
7. Risk Assessment

Keep it professional and concise.`;

    const result = await model.generateContent(prompt);
    return result.response.text();
  } catch {
    return generateFallbackBRDText(insights);
  }
}

function generateFallbackBRDText(insights) {
  return `# Business Requirements Document: ${insights.projectName || 'Project Alpha'}

## 1. Executive Summary
${insights.executiveSummary || 'This document outlines the business requirements for the project.'}

## 2. Business Objectives
${(insights.businessObjectives || []).map(o => `- ${o}`).join('\n')}

## 3. Functional Requirements
${(insights.functionalRequirements || []).map(r => `- **${r.id}**: ${r.requirement} (Priority: ${r.priority})`).join('\n')}

## 4. Non-Functional Requirements
${(insights.nonFunctionalRequirements || []).map(r => `- **${r.id}**: ${r.requirement}`).join('\n')}

## 5. Stakeholders
${(insights.stakeholders || []).map(s => `- **${s.name}** (${s.role}): ${s.interest} interest`).join('\n')}
`;
}

function generateFallbackInsights() {
  return {
    confidenceScore: 87,
    projectName: 'Project Alpha',
    executiveSummary: 'This Business Requirements Document captures all functional and non-functional requirements extracted from communications.',
    businessObjectives: ['Improve user experience', 'Automate reporting workflows', 'Enable multi-channel integration'],
    functionalRequirements: [
      { id: 'FR-01', requirement: 'User Login with OTP', priority: 'High', source: 'Meeting #3' },
      { id: 'FR-02', requirement: 'Dashboard with Analytics', priority: 'Medium', source: 'Email Thread' },
      { id: 'FR-03', requirement: 'Export Reports to PDF', priority: 'Medium', source: 'Email Thread' },
      { id: 'FR-04', requirement: 'Role-based Access Control', priority: 'High', source: 'Email Thread' },
      { id: 'FR-05', requirement: 'Real-time Notifications', priority: 'Medium', source: 'Chat Messages' },
      { id: 'FR-06', requirement: 'API Integration Support', priority: 'High', source: 'Meeting #1' },
      { id: 'FR-07', requirement: 'Audit Trail Logging', priority: 'High', source: 'Email Thread' },
      { id: 'FR-08', requirement: 'Multi-language Support', priority: 'Low', source: 'Meeting #3' },
    ],
    nonFunctionalRequirements: [
      { id: 'NFR-01', requirement: 'System uptime 99.9%', priority: 'High', source: 'SLA Document' },
      { id: 'NFR-02', requirement: 'Page load < 2 seconds', priority: 'Medium', source: 'Email Thread' },
      { id: 'NFR-03', requirement: 'GDPR compliance', priority: 'High', source: 'Legal Team' },
      { id: 'NFR-04', requirement: 'Mobile responsive design', priority: 'Medium', source: 'Meeting #2' },
      { id: 'NFR-05', requirement: 'Data encryption at rest', priority: 'High', source: 'Security Audit' },
    ],
    keyDecisions: [
      { id: 'KD-01', decision: 'Use cloud-based infrastructure', madeBy: 'Tech Lead', date: '2024-01-15' },
      { id: 'KD-02', decision: 'Adopt microservices architecture', madeBy: 'CTO', date: '2024-01-20' },
      { id: 'KD-03', decision: 'Prioritize mobile-first design', madeBy: 'Product Manager', date: '2024-02-01' },
      { id: 'KD-04', decision: 'Integrate Gemini AI for automation', madeBy: 'AI Team', date: '2024-02-10' },
    ],
    stakeholders: [
      { name: 'John Smith', role: 'Product Manager', interest: 'High' },
      { name: 'Sarah Lee', role: 'Tech Lead', interest: 'High' },
      { name: 'Mike Johnson', role: 'Business Analyst', interest: 'Medium' },
      { name: 'Lisa Chen', role: 'End User Representative', interest: 'Medium' },
    ],
    timeline: [
      { milestone: 'Requirements Gathering', date: '2024-01-31', status: 'Completed' },
      { milestone: 'Design Phase', date: '2024-02-28', status: 'Completed' },
      { milestone: 'Development Sprint 1', date: '2024-03-31', status: 'In Progress' },
      { milestone: 'UAT & Launch', date: '2024-04-30', status: 'Planned' },
    ]
  };
}

// Serve React App for any unknown route
app.get('*', (req, res) => {
  res.sendFile(path.join(__dirname, '../frontend/build', 'index.html'));
});
app.listen(PORT, () => {
  console.log(`ðŸš€ BRD Intelligence Agent Backend running on http://localhost:${PORT}`);
  console.log(`ðŸ“‹ API Endpoints:`);
  console.log(`   GET  /api/health`);
  console.log(`   GET  /api/dashboard`);
  console.log(`   POST /api/upload`);
  console.log(`   POST /api/analyze/:fileId`);
  console.log(`   GET  /api/analysis/:analysisId/status`);
  console.log(`   GET  /api/brd/:brdId`);
  console.log(`   GET  /api/brd/:brdId/insights`);
  console.log(`   GET  /api/brds`);
  console.log(`   POST /api/brd/:brdId/chat`);
});
